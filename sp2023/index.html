<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">

    <meta property="og:site_name" content="CSCI 601.771 (Self-supervised Models)">
    <meta property="og:type" content="article">
    <meta property="og:title" content="CSCI 601.771 (Self-supervised Models)">
    <meta property="og:description" content="Discussing latest breakthroughs in self-supervised language models">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="CSCI 601.771: Self-supervised Models">
    <meta name="twitter:description" content="Discussing latest breakthroughs in self-supervised language models">
    <meta name="twitter:url" content="https://self-supervised.cs.jhu.edu/">

    <title>CSCI 601.471/671: Self-supervised Models </title>

    <!-- bootstrap -->
    <link rel="stylesheet" href="files/bootstrap.min.css">

    <!-- Google fonts -->
    <link href="files/fonts.css" rel="stylesheet" type="text/css">

    <link rel="stylesheet" type="text/css" href="files/style.css">
    <link rel="stylesheet" href="files/font-awesome.min.css">

    <!--favicon-->
    <link rel="shortcut icon" href="files/favicon.ico"/>

</head>

<body data-new-gr-c-s-check-loaded="14.1063.0" data-gr-ext-installed="">

<!-- <script src="header.js"></script> -->
<!-- Navbar -->
<nav class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <a class="navbar-brand brand" href="index.html">CSCI 601.471/671</a>
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="#course">Content</a></li>
                <li><a href="#schedule">Schedule</a></li>
                <li><a href="#project">Project</a></li>
                <li><a href="https://github.com/JHU-CLSP/csci-601-771-self-supervised-models">Suggest an edit</a></li>
            </ul>
        </div>
    </div>
</nav>

<!-- Header -->
<div id="header" style="text-align:center">
    <!--    <img src="files/blank.png" class="logo-left">-->
    <a href="https://www.cs.jhu.edu/">
        <img src="files/jhu_shield.png" class="logo-right">
    </a>
    <!--    <a href="https://www.clsp.jhu.edu/">-->
    <!--        <img src="files/clsp-logo.png" class="logo-right">-->
    <!--    </a>-->
    <h1>CSCI 601.471/671 NLP: Self-supervised Models</h1>
    <h3>Johns Hopkins University - Spring 2023</h3>
    <div style="clear:both;"></div>
</div>

<!-- Intro -->
<div class="container sec" id="intro">
    <p>
        The rise of massive self-supervised (pre-trained) models have transformed various data-driven fields such as
        natural language processing (NLP). In this course, students will gain a thorough introduction to self-supervised
        learning techniques for NLP applications. Through lectures, assignments, and a final project, students will
        learn the necessary skills to design, implement, and understand their own self-supervised neural network models,
        using the Pytorch framework.
    </p>

    <p>
        <b> Note:</b> The course is different from <a href="https://self-supervised.cs.jhu.edu/fa2022/">601.771</a>
        (offered in the fall semesters) which involves reading recent papers and is geared toward grad students that
        want to specialize in the latest developments in self-supervised models.
    </p>

    <p>
        <strong>Prerequisites</strong>:
        (1) Data Structures (601.226),
        (2) All the class assignments will be in Python/PyTorch. If you don’t know Python or PyTorch but have experience
        in other programming languages (Java, C++, etc.) you can probably pick Python/PyTorch pretty quickly.
        (3) Calculus and linear algebra: you should be comfortable with matrix operations (matrix multiplication,
        transpose, inverse, dot product, gradients).
        (4) Probability: basic probability properties (conditionals, marginals, mean, standard deviation), distributions
        (gaussian, categorical).
        (5) Background in Natural Language Processing & Machine Learning or having finished one of the relevant courses
        such as Machine Learning (475.675), Artificial Intelligence (464.664), Natural Language Processing (600.465),
        Machine Translation (600.468), or Introduction to HLT (601.467/667).
    </p>

</div>

<!-- Staff Info -->
<div class="sechighlight">
    <div class="container sec" id="people">
        <div class="col-md-5" style="width: 100%; text-align: center">
            <br>
            <!--            <h3>Instructors</h3>-->
            <div class="instructor">
                <a target="_blank" rel="noopener noreferrer" href="http://danielkhashabi.com/">
                    <div class="instructorphoto"><img src="files/daniel.jpeg" alt="missing image"></div>
                    <div>Daniel Khashabi<br>Instructor</div>
                </a>
                <div></div>
            </div>
            <div class="instructor">
                <a target="_blank" rel="noopener noreferrer" href="?">
                    <div class="instructorphoto"><img src="files/adam.jpeg" alt="missing image"></div>
                    <div>Adam Byerly<br>Teaching Assistant</div>
                </a>
            </div>
            <div class="instructor">
                <a target="_blank" rel="noopener noreferrer" href="?">
                    <div class="instructorphoto"><img src="files/blank.png" alt="missing image"></div>
                    <div>Lingfeng Shen<br>Course Assistant</div>
                </a>
            </div>
            <div class="instructor">
                <a target="_blank" rel="noopener noreferrer" href="?">
                    <div class="instructorphoto"><img src="files/blank.png" alt="missing image"></div>
                    <div>TBD <br>Course Assistant</div>
                </a>
            </div>
            <div class="instructor">
                <a target="_blank" rel="noopener noreferrer" href="?">
                    <div class="instructorphoto"><img src="files/blank.png" alt="missing image"></div>
                    <div>TBD <br>Course Assistant</div>
                </a>
            </div>
        </div>
    </div>
</div>

<div class="container sec" id="logistics">
    <h2>Logistics</h2>
    <ul>
        <li><b>Classes:</b> on Tuesday/Thursday 12 - 1:15 pm EST (room: TBD)</li>
        <li><b>Office hours:</b> TBD</li>
        <li><b>Contact:</b> If you have any questions about the course email the instructors (TBD: on canvas? create
            a google group?).
        </li>
        <li><b>Virtual or in-person</b>: The class will be in-person. Though there will be recordings of each class
            made available online after each class on Canvas/Panopto.
        </li>
        <li><b>Changes:</b> The instructor reserves the right to make changes to the syllabus or project due dates.
            These changes will be announced as early as possible.
        </li>
        <li><b>News and announcements:</b> All the news and announcements will be made on Canvas.</li>
        <!--            <li><b>Attendance and late work:</b>-->
        <!--                You can miss 3 sessions.-->
        <!--                Additionally, you get 2 sessions of presentation relief (i.e., you can skip 2 presentation assignments) to accommodate any deadlines you might have.-->
        <!--                If you decide to use these, make sure to email the instructor in advance (at least two days).-->
        <!--                Beyond that limit, you'd lose the attendance/presentation credits for any class you miss.-->
        <!--&lt;!&ndash;                If you miss a class without completing the corresponding assignment, you'll get a zero for that session.&ndash;&gt;-->
        <!--&lt;!&ndash;                Unfortunately you can't miss a class in which you're "presenting".&ndash;&gt;-->
        <!--&lt;!&ndash;                If you have to miss a class where you are in a "presenting" role for that session, you must find someone willing to swap presentations with (e.g., you were expected to present on Tuesday; but you swap presentations with someone who presents on Thursdays).&ndash;&gt;-->
        <!--&lt;!&ndash;                Alternatively, you must still create the presentation for that role before the class and you must find someone else to present it for you.&ndash;&gt;-->
        <!--                There's really no way to accept late work.-->
        <!--&lt;!&ndash;                for the readings since it's vital that we're all reading the same papers at the same time.&ndash;&gt;-->
        <!--            </li>-->
        <li><b>COVID:</b> Students who report symptoms associated with COVID-19 are expected not to attend class and
            to isolate themselves for at least five days and until they have been symptom-free for 24 hours.
        </li>

        <li>
            <b>Course grade:</b>
            Your grade is based on the following activities:
            (1) Semi-weekly assignments (40%),
            (2) midterm exams (30%), and
            (3) a final project (30%).
            Attendance is not mandatory (hence, 0%) but highly encouraged: participation in class is our chance to
            learn more effectively.
            [TBD: additional credits for any activities that improve the class]
        </li>

    </ul>
    <br>
</div>

<div class="container sec" id="links">
    <h2>Key links</h2>
    <ul>
        <li><a href="">Piazza</a> for discussion and announcements. Sign up, follow, and participate!</li>
        <li><a href="">Gradescope</a> for submitting your assignments.</li>
    </ul>
</div>

<div class="container sec" id="course">
    <h2>Content</h2>
    <p>
        Each session will involve the instructor-led presentation on a focused topic self-supervised statistical models.
        There will be weekly assignments related to class presentations, two midterm exams and a final project.
    </p>

    <h3>~Weekly Assignments</h3>
    <p>
        The course has 10 weekly assignments which will improve both your theoretical understanding
        and your practical skills. All assignments contain both written questions and programming parts.
    </p>
    <p>
        Here are a tentative list of topics for the assignments:
    </p>

    <table class="table">
        <colgroup>
            <col style="width:1%">
            <col style="width:10%">
            <col style="width:35%">
        </colgroup>
        <thead>
        <tr class="active">
            <th>#</th>
            <th>Concept</th>
            <th>Practice</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>#1</td>
            <td>Algebra, calculus, probability recap</td>
            <td>PyTorch introduction, implementing Skip-Gram model, classification, evaluation, comparison to basic
                features (unigrams, bigrams) and existing embeddings (Word2Vec, GloVe)
            </td>
        </tr>
        <tr>
            <td>#2</td>
            <td>TBD</td>
            <td>Implementing Skim-gram with negative sampling, quantifying quality vs speed, co-occurrence matrix and
                factorization, classification and comparison
            </td>
        </tr>
        <tr>
            <td>#3</td>
            <td>TBD</td>
            <td>Automatic differentiation, computation graph, how to use PyTorch on GPUs, basic feedforward network and
                back-propagation, Word2Vec as a feedforward net with automatic differentiation
            </td>
        </tr>
        <tr>
            <td>#4</td>
            <td>TBD</td>
            <td>Neural language model with feedforward network, evaluating language modeling, comparison to count-based
                model, comparing the representation to Word2Vec
            </td>
        </tr>
        <tr>
            <td>#5</td>
            <td>TBD</td>
            <td>Recurrent neural language model and evaluation, comparison to all the earlier models</td>
        </tr>
        <tr>
            <td>#6</td>
            <td>TBD</td>
            <td>Transformer-based language model, comparison to the earlier models</td>
        </tr>
        <tr>
            <td>#7</td>
            <td>TBD</td>
            <td>Decoding language models: greedy, nucleus, typical. Various issues related to text generation.</td>
        </tr>
        <tr>
            <td>#8</td>
            <td>TBD</td>
            <td>Fine-tuning, prefix-tuning, adapting existing models, comparison to the earlier models.
                [Mis]-Interpreting continuous prompts.
            </td>
        </tr>
        <tr>
            <td>#9</td>
            <td>TBD</td>
            <td>Modifying Transformer for long contexts</td>
        </tr>
        <tr>
            <td>#10</td>
            <td>TBD</td>
            <td>In-context learning</td>
        </tr>
        <tr>
            <td>#11</td>
            <td>TBD</td>
            <td>Retrieval-augmented language models</td>
        </tr>
        <tr>
            <td>#12</td>
            <td>TBD</td>
            <td>Alignment with human feedback</td>
        </tr>
        <tr>
            <td>#13</td>
            <td>TBD</td>
            <td></td>
        </tr>

        </tbody>
    </table>


    <ul>
<!--        <li><b>Assignment deadlines:</b> .</li>-->
        <li><b>Submission:</b> Assignments must be submitted via GradeScope</li>
        <li><b>Collaboration:</b> Study groups are allowed, but students must understand and complete their own
            assignments, and hand in one assignment per student. If you worked in a group, please put the names of the
            members of your study group at the top of your assignment. Please ask if you have any questions about the
            collaboration policy.
        </li>
        <!--        <li><b>Late start:</b>If the result gives you a higher grade, we will not use your assignment 1 score, and we will give you an assignment grade based on counting each of assignments 2–5 at 13.5%.</li>-->
        <li><b>Honor code:</b>
        We expect students to not look at solutions or implementations online. Like all other classes at Stanford, we
        take the student Honor Code seriously. We sometimes use automated methods to detect overly similar assignment
        solutions.</li>
        <li><b>Late days:</b>
            Each student has 10 late days to use. A late day extends the deadline 24 hours. You can use up to 3 late
            days per assignment (including all five assignments, project proposal, project milestone, and project final
            report). Teams can share late days between members. For example, a group of three people must have at least
            six late
            days between them to extend the deadline by two days. If any late days are being shared, this must be
            clearly marked at the beginning of the report. Once you have
            used all 10 late days, the penalty is 1% off the final course grade for each additional late day.
        </li>
    </ul>

    <h3>Midterm exams</h3>
    <p>
        TBD
    </p>

    <h3>Reference text</h3>
    <p>
        There is no required text. Though the following can be useful:
    </p>
    <ul>
        <li><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing, Jurafsky and Martin</a>
        </li>
        <li><a href="https://catalyst.library.jhu.edu/catalog/bib_9689868">Natural language processing with PyTorch,
            Rao, and McMahan</a></li>
        <li><a href="https://catalyst.library.jhu.edu/catalog/bib_9697352">Transformers for Natural Language Processing,
            Rothman </a></li>
        <li><a href="https://catalyst.library.jhu.edu/catalog/bib_9822241">Neural Network Methods for Natural Language
            Processing, Goldberg </a></li>
        <li><a href="https://d2l.ai/">Dive into Deep Learning, Zhang et al. </a></li>
    </ul>


    <h3>Final project</h3>
    <p>
        TBD
    </p>

</div>

<!--[TODO: how to change the roles? consult with the instructor]-->


<div class="container sec" id="schedule" style="margin-top:-20px">
    <br>
    <h2>Schedule</h2>
    <p> The current class schedule is below (subject to change): </p>

    <table class="table">
        <colgroup>
            <col style="width:12%">
            <col style="width:30%">
            <col style="width:32%">
            <col style="width:10%">
            <col style="width:10%">
        </colgroup>
        <thead>
        <tr class="active">
            <th>Date</th>
            <th>Topic</th>
            <th>Course Materials</th>
            <th>Events</th>
            <th>Deadlines</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>#1 - Tue Jan 24</td>
            <td>
                Course overview
                <br>
                Plan and expectations
                <br>
                 [<a href="https://livejohnshopkins-my.sharepoint.com/:p:/g/personal/dkhasha1_jh_edu/EcXd1egC6fJBs9G8W2J1ndkBXT78Jv_pSNSQcXaGhrr1zw?e=iiSLkK">slides</a>]
            </td>
            <td>
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Self-supervised Word Representations</b>
            </td>
        </tr>
        <tr>
            <td>#2 - Thu Jan 26</td>
            <td>
                Human language and word meaning <br>
                Word2vec overview <br>
                Word2vec objective function <br>
                 [<a href="https://livejohnshopkins-my.sharepoint.com/:p:/g/personal/dkhasha1_jh_edu/ESGXc8UidHVLlq2GRHPj8_8BZiV6_FlpQ7-XBULiQoZlSw?e=gfffqc">slides</a>]
            </td>
            <td></td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#3 - Tue Jan 31</td>
            <td>
                Word2vec objective function (continued)<br>
                Inspecting the resulting word vectors <br>
                Evaluating word vectors <br>
                [<a href="https://livejohnshopkins-my.sharepoint.com/:p:/g/personal/dkhasha1_jh_edu/ESGXc8UidHVLlq2GRHPj8_8BZiV6_FlpQ7-XBULiQoZlSw?e=gfffqc">slides</a>]
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Self-Supervised Representation of Feedforward Neural Language Models</b>
            </td>
        </tr>
        <tr>
            <td>#4 - Thu Feb 2</td>
            <td>
                Word2vec limitations<br>
                Feed-forward nets for modeling context <br>
                Word2vec as simple feed-forward net <br>
                A fixed-window feedforward language model <br>
                Neural nets: brief history
                <br>
                [<a href="files/?">slides</a>]
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight2">
            <td>Fri  Feb 3</td>
            <td>PyTorch Review Session (virtual) </td>
            <td>Time: TBD </td>
            <td></td>
            <td></td>
        </tr>
        <tr>
            <td>#5 - Tue Feb 7</td>
            <td>
                Analytical back-propagation <br>
                Automatic differentiation and computation graph <br>
                Practical tips for training neural networks <br>
                Evaluating language generation
<!--                <br>-->
<!--                [<a href="files/?">slides</a>]-->
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Self-Supervised Representation of Recurrent Neural Language Models</b>
            </td>
        </tr>
        <tr>
            <td>#6 - Thu Feb 9</td>
            <td>
                Limitations of feed-forward language models <br>
                Recurrent neural networks <br>
                Sequence-to-sequence model <br>
                Training Seq2Seq models <br>

<!--                <br>-->
<!--                [<a href="files/?">slides</a>]-->
            </td>
            <td>
            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#7 - Tue Feb 14</td>
            <td>
                Vanishing/exploding gradients <br>
                Fancy versions of RNNs: <br>
                    - Bidirectional RNN,<br>
                    - stacked RNN, etc. <br>
                Seq2Seq with Attention <br>
                Aside: Input units: words, subwords, characters, byte
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Self-Supervised Representation of Transformer Language Models</b>
            </td>
        </tr>
        <tr>
            <td>#8 - Thu Feb 16</td>
            <td>
                Self-attention: how it works   <br>
                Positional embeddings  <br>
                Positional complexity  <br>
                Self-attention: hacks and variants <br>
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight2">
            <td>Fri  Feb 17</td>
            <td>PyTorch Review Session (virtual) </td>
            <td>Time: TBD </td>
            <td></td>
            <td></td>
        </tr>
        <tr>
            <td>#9 - Tue Feb 21</td>
            <td>
                Transformer architecture <br>
                Various pre-training objective functions <br>
                Existing models: BERT, RoBERTa, T5, GPT<br>
                Scaling laws <br>
                Multilingual properties <br>
                Pre-training hacks
            </td>
            <td>
            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Doing Things with Language Models</b>
            </td>
        </tr>
        <tr>
            <td>#10 - Thu Feb 23</td>
            <td>
                Generation and surprisal <br>
                Text generation algorithms:<br>
                 - greedy decoding, <br>
                 - stochastic (top-k, nucleus) <br>
                - exhaustive search <br>
                - beam search <br>
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#11 - Tue Feb 28</td>
            <td>
                Adapting models with parameter change <br>
                Fine-tuning <br>
                Prefix-tuning <br>
                Adaptors <br>
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#12 - Thu Mar 2</td>
            <td>
                Adapting models with prompting <br>
                In-context learning <br>
                Multi-step reasoning <br>
                Connection to supervised learning <br>
                Failure modes of in-context learning <br>
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#13 - Tue Mar 7</td>
            <td>
                Hallucination issue <br>
                Calibrating model uncertainties <br>
                - Consistency <br>
                - Sensitivity <br>
                - Mutual information <br>
                - Flatness <br>
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Language Models and Long Context</b>
            </td>
        </tr>

        <tr>
            <td>#14 - Thu Mar 9</td>
            <td>tbd</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>

<!--        <tr class="sechighlight">-->
<!--            <td colspan="5" >-->
<!--                <b> ⬇️ &#45;&#45; Social Concerns</b>-->
<!--            </td>-->
<!--        </tr>-->


        <tr>
            <td>#15 - Tue Mar 14</td>
            <td>tbd</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Social Concerns and Alignment with Human Values </b>
            </td>
        </tr>
        <tr>
            <td>#16 - Thu Mar 16</td>
            <td>
                Bias, fairness and toxic language <br>
                Moral frameworks and reasoning <br>
                Truthfulness and veracity <br>
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>

        <tr class="sechighlight4 centered">
            <td>#17 - Tue Mar 21</td>
            <td>No Class - Spring Break</td>
            <td>

            </td>
            <td>
                <!--                <ol>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight4 centered">
            <td>#18 - Thu Mar 23</td>
            <td>No Class - Spring Break</td>
            <td>

            </td>
            <td>
                <!--                <ol>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                </ol>-->
            </td>
            <td></td>
        </tr>

        <tr>
            <td>#19 - Tue Mar 28</td>
            <td>tbd</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#20 - Thu Mar 30</td>
            <td>tbd</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Memorization, Security and Privacy </b>
            </td>
        </tr>

        <tr>
            <td>#21 - Tue Apr 4</td>
            <td>tbd</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#22 - Thu Apr 6</td>
            <td>tbd</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Self-Supervised Learning Text and Other Modalities</b>
            </td>
        </tr>
        <tr>
            <td>#23 - Tue Apr 11</td>
            <td>Joint representation of language and programming languages</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#24 - Thu Apr 13</td>
            <td>
                Language grounded in structured layouts (web pages, phone apps, ...)
<!--                <br>-->
<!--                Language and app layouts-->
            </td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr>
            <td>#25 - Tue Apr 18</td>
            <td>Joint representation of language and visual information</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>

        </tr>
        <tr>
            <td>#26 - Thu Apr 20</td>
            <td>Joint representation of text and speech signals</td>
            <td>

            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight">
            <td colspan="5" >
                <b> ⬇️ -- Future of Self-Supervised Models</b>
            </td>
        </tr>
        <tr>
            <td>#27 - Tue Apr 25</td>
            <td>
                Bias/fairness concerns and feedback loops <br>
                Environmental concerns <br>
                Privacy and security issues <br>
                Legal issues
            </td>
            <td>
            </td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
        </tr>
        <tr>
            <td>#28 - Thu Apr 27</td>
            <td>
                Future of self-supervised models <br>
                Availability of data <br>
                Availability of compute <br>
                Limitations and open problems
            </td>
            <td></td>
            <td>
<!--                <ol>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                    <li><a href="">tbd</a></li>-->
<!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight4 centered">
            <td>#29 - Tue May 2</td>
            <td>No Class - Reading Days</td>
            <td></td>
            <td>
                <!--                <ol>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <tr class="sechighlight4 centered">
            <td>#30 - Thu May 4</td>
            <td>No Class - Reading Days</td>
            <td>

            </td>
            <td>
                <!--                <ol>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                    <li><a href="">tbd</a></li>-->
                <!--                </ol>-->
            </td>
            <td></td>
        </tr>
        <!--        <tr>-->
        <!--            <td>#31 - Tue May 9</td>-->
        <!--            <td>tbd</td>-->
        <!--            <td>-->

        <!--            </td>-->
        <!--            <td>-->
        <!--                <ol>-->
        <!--                    <li><a href="">tbd</a></li>-->
        <!--                    <li><a href="">tbd</a></li>-->
        <!--                </ol>-->
        <!--            </td>-->
        <!--        </tr>-->
        <!--        <tr>-->
        <!--            <td>#32 - Thu May 11</td>-->
        <!--            <td>tbd</td>-->
        <!--            <td>-->

        <!--            </td>-->
        <!--            <td>-->
        <!--                <ol>-->
        <!--                    <li><a href="">tbd</a></li>-->
        <!--                    <li><a href="">tbd</a></li>-->
        <!--                </ol>-->
        <!--            </td>-->
        <!--        </tr>-->

        <tr class="sechighlight2 centered">
            <td> TBD
                <!--                <br> 9 AM - 12 PM<a href="https://studentaffairs.jhu.edu/registrar/wp-content/uploads/sites/23/2022/08/Fall-2022-Final-Exam-Schedule.pdf"> <sup><b>*</b></sup></a> -->
            </td>
            <td>Final project presentation</td>
            <td>
                <!--                <a href="https://livejohnshopkins-my.sharepoint.com/:p:/g/personal/dkhasha1_jh_edu/Eb7jCHgIa2hOmUiehX1_DT8BGBMDPI9soYPGypvsppYLwQ?e=1ha9Wb">Slides</a><br>-->
            </td>
            <td></td>
            <td></td>
        </tr>

        <tr class="sechighlight2 centered">
            <td> TBD</td>
            <td colspan="2">Final report submission deadline</td>
            <td></td>
            <td></td>
        </tr>
        </tbody>
    </table>
</div>

<div class="container sechighlight" id="project">
    <h2>Project</h2>
    <p>
        All students in the class will write a "mini-paper" as a final project. The topic of this project is open-ended.
        This project, for example, can focus on demonstrate systemic limitations of a prior work
        or suggesting improvements on methods or benchmarks discussed in the class.
        <!--        reproducing one or more papers covered in the class (or relevant works)-->
        <!--        or extending them.-->
    </p>
    <ul>

        <li><b>Group work:</b> Students are encouraged to work in groups on the final project (team sizes limited to 2
            or
            3 people).
        </li>
        <li><b>Project proposals:</b> All groups will be required to submit a project proposal due on Friday Sept 30.
            The project proposal is a single-paragraph description of what you intend to do (experiments, datasets,
            methods, etc.) The instructor(s) will provide feedback on these ideas to help the teams with finding a
            concrete idea. There will be lightning presentations of the finalized proposals on Thursday Oct 13.
        </li>
        <li><b>Midway progress presentation:</b> Groups will present their halfway progress during a mid-way project
            presentation on Tuesday Nov 15. This is expected to be a short presentation discussing the progress made for
            each project and
            any remaining hurdles.
        </li>
        <li><b>Final presentation:</b> The final project presentation will be during the final exam period. All students
            in each group are required to present some material during the final presentation.
        </li>
        <li><b>Final Report:</b> Students should write code and carry out additional experiments and then write up the
            results in a standard conference paper format (<a
                    href="https://www.overleaf.com/latex/templates/neurips-2022/kxymzbjpwsqx">template</a>).
            The length of the final report should be 5 to 8 pages. Note that longer reports are not necessarily better.
            Students in groups are required to include a “contributions” section concretely lists each
            author’s contributions (see Section 8 of this paper, for example).
            <!--            The final reports are due TBD.-->
        </li>
    </ul>
</div>

<div class="container sec" id="resources">
    <h2>Relevant Resources</h2>
    <p>Here are several resources available for free:</p>
    <ul>
        <li>Compute resources:
            <ul>
                <li>Grad students should have access to the graduate grid which has GPUs.</li>
                <li>Undergraduate students should have access to the undergrad grid.</li>
                <li><a href="https://colab.research.google.com/">Google Colab</a> provides free GPU usage for up to 12
                    hours/day for academic purposes. One can obtain <a
                            href="https://medium.com/@yufengg/how-to-upgrade-colab-with-more-compute-64d53a9b05dc"> more
                        compute on Colab</a> with relatively minimal pay.
                </li>
                <li>Google offers <a href="https://sites.research.google/trc/about/">research TPU credits</a>.</li>
                <li><a href="https://www.kaggle.com/general/108481">Kaggle</a> offers GPUs for its users.</li>
                <li><a href="https://aws.amazon.com/education/awseducate/">AWS</a> and <a
                        href="https://azure.microsoft.com/en-us/free/students/">Azure</a> both offer welcome credits to
                    students.
                </li>
                <li>If you need credits to use GPT3, discuss it with the instructor.</li>
            </ul>
        </li>
        <li>Demos:
            <ul>
                <li><a href="https://6b.eleuther.ai">GPT-J demo</a></li>
                <li><a href="https://opt.alpa.ai/#generation">OPT demo</a></li>
                <li><a href="https://huggingface.co/bigscience/bloom">BLOOM demo</a></li>
                <li><a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL-E mini demo</a></li>
                <li><a href="https://c4-search.apps.allenai.org">A queryable interface to C4</a></li>
                <li><a href="https://vision-explorer.allenai.org">AllenAI vision demo</a></li>
                <li><a href="https://demo.allennlp.org">AllenNLP demo</a></li>
                <li><a href="https://unqover.apps.allenai.org/">Social stereotypes in models</a></li>
                <li><a href="https://blenderbot.ai/">Meta's BlenderBot demo</a></li>
                <li><a href="https://beta.dreamstudio.ai/">DreamStudio image generation demo</a></li>
                <li><a href="https://google-research.github.io/seanet/audiolm/examples/">Examples from AudioLM</a></li>
                <li><a href="https://github.com/CompVis/stable-diffusion">Stable Diffusion model weights </a></li>

                <li><a href="https://instructions.apps.allenai.org/">A repository of language tasks and their
                    instructions</a></li>
            </ul>
        </li>
        <li>Tutorials:</li>
        <ul>
            <li><a href="https://pytorch.org/tutorials/">These tutorials</a> do a good job of introducing PyTorch.</li>
            <li>A <a href="https://huggingface.co/course/chapter1/1">course</a> on Huggingface's Transformers library.
            </li>
            <li><a href="https://huggingface.co/blog/stable_diffusion">Tutorial on Huggingface's Diffusers library </a>
            </li>
            <li><a href="https://d2l.ai/">Dive into Deep Learning</a>: Interactive deep learning book with code, math,
                and discussions.
            </li>
        </ul>
    </ul>
    <p>
        Besides these resources, we will try our best to satisfy individual needs through discussion.
    </p>
</div>

<div class="container sec" id="relevant-courses">
    <h2>Relevant Courses at Hopkins</h2>
    <p>Has some overlap with Natural Language Processing (EN.601/665) and “Introduction to Human Language Technology”
        (601.467/667) but they focus on different topics. </p>
</div>


<div class="container sec" id="conduct">
    <h2>Conduct</h2>
    <p>
        Since this is a discussion class, it's especially important that we respect everyone's perspective and input. In
        particular, I value the perspectives of individuals from all backgrounds reflecting the diversity of our
        students. I will strive to make this classroom an inclusive space for all students. Please let me know if there
        is anything I can do to improve.
    </p>
    <p>
        This course will have a zero-tolerance philosophy regarding <a
            href="https://www.cs.jhu.edu/academic-programs/academic-integrity-code/">plagiarism or other forms of
        cheating</a>, and incidents
        of academic dishonesty will be reported. A student who has doubts about how the Honor Code applies to this
        course should obtain specific guidance from the course instructor before submitting the respective assignment.
    </p>
    <p>
        The Johns Hopkins University is committed to equal opportunity for its faculty, staff, and students.
        To that end, the university does not discriminate on the basis of sex, gender, marital status, pregnancy, race,
        color, ethnicity, national origin, age, disability, religion, sexual orientation, gender identity or expression,
        veteran status, military status, immigration status or other legally protected characteristic.
        The University's <a
            href="https://oie.jhu.edu/policies-and-laws/JHU-Discrimination-and-Harassment-Policy-and-Procedures-7.1.21-Present">Discrimination
        and Harassment Policy and Procedures</a> provides information on how to report or file a complaint of
        discrimination or harassment based on any of the protected statuses listed in the earlier sentence, and the
        University’s prompt and equitable response to such complaints.
    </p>
</div>


<!-- jQuery and Bootstrap -->
<script src="files/jquery.min.js"></script>
<script src="files/bootstrap.min.js"></script>


</body>
</html>
